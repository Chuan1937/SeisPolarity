{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: center; margin-bottom: 20px;\">\n",
    "  <img src=\"../docs/_static/seispolarity_logo_title.svg\">\n",
    "</div>\n",
    "7\n",
    "---\n",
    "\n",
    "## Training API Usage Example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for training\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "from seispolarity.data.base import WaveformDataset\n",
    "from seispolarity.models import SCSN\n",
    "from seispolarity.training import Trainer, TrainingConfig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "CUDA device: NVIDIA GeForce RTX 4060 Ti\n",
      "CUDA memory: 8.59 GB\n"
     ]
    }
   ],
   "source": [
    "# Select device based on availability\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Additional device info\n",
    "if DEVICE == \"cuda\":\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "elif DEVICE == \"mps\":\n",
    "    print(f\"MPS device available\")\n",
    "else:\n",
    "    print(f\"CPU device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Configuration\n",
    "\n",
    "Configure the dataset path and parameters for loading seismic waveform data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset path: /mnt/f/AI_Seismic_Data/scsn/scsn_p_2000_2017_6sec_0.5r_fm_train.hdf5\n",
      "Output directory: ./checkpoints_ross_scsn\n"
     ]
    }
   ],
   "source": [
    "# Dataset path configuration\n",
    "# Option 1: Use local file\n",
    "# DATA_PATH = \"/path/to/your/dataset.hdf5\"\n",
    "\n",
    "# Option 2: Use automatic download (uncomment to use)\n",
    "# from seispolarity.data import SCSNData\n",
    "# scsn_processor = SCSNData(output_dir=\"./datasets\")\n",
    "# DATA_PATH = scsn_processor.download()\n",
    "# print(DATA_PATH)\n",
    "\n",
    "# For this example, we'll use a placeholder path\n",
    "# Replace this with your actual dataset path\n",
    "DATA_PATH = r\"/mnt/f/AI_Seismic_Data/scsn/scsn_p_2000_2017_6sec_0.5r_fm_train.hdf5\"\n",
    "\n",
    "# Output directory for checkpoints\n",
    "OUT_DIR = \"./checkpoints_ross_scsn\"\n",
    "\n",
    "print(f\"Dataset path: {DATA_PATH}\")\n",
    "print(f\"Output directory: {OUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data parameters:\n",
      "  Preload data: True\n",
      "  Allowed labels: [0, 1, 2]\n",
      "  P-wave position: 300\n",
      "  Crop left: 200 samples\n",
      "  Crop right: 200 samples\n",
      "  Output window: 400 samples (100-500)\n"
     ]
    }
   ],
   "source": [
    "# Data loading parameters\n",
    "PRELOAD = True\n",
    "ALLOWED_LABELS = [0, 1, 2]\n",
    "CROP_LEFT = 200\n",
    "CROP_RIGHT = 200\n",
    "\n",
    "# For SCSN dataset:\n",
    "# - p_pick_position: Fixed P-wave position in the waveform (sample 300)\n",
    "# - crop_left: Number of samples to keep before P-wave\n",
    "# - crop_right: Number of samples to keep after P-wave\n",
    "# Result: 400-point window centered on P-wave (100-500)\n",
    "\n",
    "print(f\"Data parameters:\")\n",
    "print(f\"  Preload data: {PRELOAD}\")\n",
    "print(f\"  Allowed labels: {ALLOWED_LABELS}\")\n",
    "print(f\"  P-wave position: 300\")\n",
    "print(f\"  Crop left: {CROP_LEFT} samples\")\n",
    "print(f\"  Crop right: {CROP_RIGHT} samples\")\n",
    "print(f\"  Output window: 400 samples (100-500)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-07 10:27:37,587 - seispolarity.data - INFO - Initialized Flat Dataset from scsn_p_2000_2017_6sec_0.5r_fm_train.hdf5 with 2494194 samples.\n",
      "2026-02-07 10:27:37,587 | seispolarity.data | INFO | Initialized Flat Dataset from scsn_p_2000_2017_6sec_0.5r_fm_train.hdf5 with 2494194 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-07 10:27:37,607 - seispolarity.data - INFO - Built index with 2494194 samples (filtered from 2494194)\n",
      "2026-02-07 10:27:37,607 | seispolarity.data | INFO | Built index with 2494194 samples (filtered from 2494194)\n",
      "2026-02-07 10:27:37,611 - seispolarity.data - INFO - Loading 2494194 samples into RAM...\n",
      "2026-02-07 10:27:37,611 | seispolarity.data | INFO | Loading 2494194 samples into RAM...\n",
      "2026-02-07 10:27:37,614 - seispolarity.data - INFO - Loading Metadata...\n",
      "2026-02-07 10:27:37,614 | seispolarity.data | INFO | Loading Metadata...\n",
      "Loading RAM: 100%|██████████| 2494194/2494194 [00:16<00:00, 153521.92samples/s]\n",
      "2026-02-07 10:27:53,872 - seispolarity.data - INFO - RAM Load Complete.\n",
      "2026-02-07 10:27:53,872 | seispolarity.data | INFO | RAM Load Complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created: SCSN_Train\n",
      "Dataset length: 2494194\n",
      "Allowed labels: [0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "# Create waveform dataset\n",
    "dataset = WaveformDataset(\n",
    "    path=DATA_PATH,\n",
    "    name=\"SCSN_Train\",\n",
    "    preload=PRELOAD,\n",
    "    allowed_labels=ALLOWED_LABELS,\n",
    "    data_key=\"X\",\n",
    "    label_key=\"Y\",\n",
    "    clarity_key=None,\n",
    "    pick_key=None,\n",
    "    metadata_keys=[],\n",
    "    p_pick_position=300,\n",
    "    crop_left=CROP_LEFT,\n",
    "    crop_right=CROP_RIGHT\n",
    ")\n",
    "\n",
    "print(f\"Dataset created: {dataset._name}\")\n",
    "print(f\"Dataset length: {len(dataset)}\")\n",
    "print(f\"Allowed labels: {dataset.allowed_labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training configuration:\n",
      "  Epochs: 50\n",
      "  Batch size: 256\n",
      "  Learning rate: 0.001\n",
      "  Num workers: 4\n",
      "  Device: cuda\n",
      "  Train/Val/Test split: 0.8/0.1/0.1\n",
      "  Early stopping patience: 5\n",
      "  Random seed: 36\n"
     ]
    }
   ],
   "source": [
    "# Training parameters\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 256\n",
    "LR = 1e-3\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "# Create training configuration\n",
    "config = TrainingConfig(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    learning_rate=LR,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    device=DEVICE,\n",
    "    checkpoint_dir=OUT_DIR,\n",
    "    label_key=\"label\",\n",
    "    train_val_split=0.8,\n",
    "    val_split=0.1,\n",
    "    test_split=0.1,\n",
    "    patience=5,\n",
    "    random_seed=36\n",
    ")\n",
    "\n",
    "print(f\"Training configuration:\")\n",
    "print(f\"  Epochs: {EPOCHS}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Learning rate: {LR}\")\n",
    "\n",
    "print(f\"  Num workers: {NUM_WORKERS}\")\n",
    "print(f\"  Device: {DEVICE}\")\n",
    "print(f\"  Train/Val/Test split: {config.train_val_split}/{config.val_split}/{config.test_split}\")\n",
    "print(f\"  Early stopping patience: {config.patience}\")\n",
    "print(f\"  Random seed: {config.random_seed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created: SCSN\n",
      "Model device: cuda\n",
      "\n",
      "Model architecture:\n",
      "SCSN(\n",
      "  (shared_backbone): SharedBackbone(\n",
      "    (sequential): Sequential(\n",
      "      (0): Conv1d(1, 32, kernel_size=(21,), stride=(1,), padding=same)\n",
      "      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (4): Conv1d(32, 64, kernel_size=(15,), stride=(1,), padding=same)\n",
      "      (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): ReLU()\n",
      "      (7): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (8): Conv1d(64, 128, kernel_size=(11,), stride=(1,), padding=same)\n",
      "      (9): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (10): ReLU()\n",
      "      (11): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (12): Flatten(start_dim=1, end_dim=-1)\n",
      "      (13): Linear(in_features=6400, out_features=512, bias=True)\n",
      "      (14): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (15): ReLU()\n",
      "      (16): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (17): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (18): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fm_head): Linear(in_features=512, out_features=3, bias=True)\n",
      ")\n",
      "\n",
      "Total parameters: 3,665,731\n",
      "Trainable parameters: 3,665,731\n",
      "Output directory created: ./checkpoints_ross_scsn\n"
     ]
    }
   ],
   "source": [
    "# Create Ross (SCSN) model\n",
    "# num_fm_classes=3: number of polarity classes (Up, Down, Unknown)\n",
    "model = SCSN(\n",
    "    num_fm_classes=3,\n",
    "    sample_rate=100.0\n",
    ")\n",
    "\n",
    "# Move model to device\n",
    "model.to(DEVICE)\n",
    "\n",
    "print(f\"Model created: {model.name}\")\n",
    "print(f\"Model device: {model.device}\")\n",
    "print(f\"\\nModel architecture:\")\n",
    "print(model)\n",
    "\n",
    "# Count model parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "# Create output directory for checkpoints\n",
    "Path(OUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Output directory created: {OUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer initialized\n",
      "Model: SCSN\n",
      "Dataset: SCSN_Train\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    dataset=dataset,\n",
    "    val_dataset=None,\n",
    "    test_dataset=None,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "print(f\"Trainer initialized\")\n",
    "print(f\"Model: {trainer.model.name}\")\n",
    "print(f\"Dataset: {trainer.dataset._name}\")\n",
    "print(f\"Device: {trainer.config.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training\n",
    "\n",
    "The trainer will:\n",
    "1. Split the dataset into train/val/test sets\n",
    "2. Train the model for the specified number of epochs\n",
    "3. Save checkpoints periodically\n",
    "4. Apply early stopping if validation accuracy doesn't improve\n",
    "5. Return the best validation accuracy and final test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "print(\"Starting training...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "best_val_acc, final_test_acc = trainer.train()\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nTraining completed!\")\n",
    "print(f\"Best validation accuracy: {best_val_acc:.4f}\")\n",
    "print(f\"Final test accuracy: {final_test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved to: checkpoints_ross_scsn/final_model.pth\n"
     ]
    }
   ],
   "source": [
    "# Save final model\n",
    "final_model_path = Path(OUT_DIR) / \"final_model.pth\"\n",
    "torch.save(model.state_dict(), final_model_path)\n",
    "\n",
    "print(f\"Final model saved to: {final_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleanup completed\n"
     ]
    }
   ],
   "source": [
    "# Clean up resources\n",
    "if not PRELOAD and hasattr(dataset, 'dataset') and hasattr(dataset.dataset, 'close'):\n",
    "    dataset.dataset.close()\n",
    "    print(\"Dataset closed\")\n",
    "else:\n",
    "    print(\"Cleanup completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seispolarity",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
