{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: center; margin-bottom: 20px;\">",
    "  <img src=\"../docs/_static/seispolarity_logo_title.svg\">",
    "</div>",
    "",
    "---",
    "",
    "## Dataset API Usage Example - PNW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for data processing and visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from seispolarity.data import PNW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PNW Dataset Automatic Download and Processing",
    "",
    "Set output directory and create PNW processor, enable automatic download function:",
    "- `auto_download=True`: automatically download missing data (if CSV and HDF5 files do not exist)",
    "- `use_hf=False`: use ModelScope (True uses Hugging Face)",
    "- `force_download=False`: do not force re-download (True will overwrite existing files)",
    "- `component_order=\"ENZ\"`: original component order in HDF5 (E-N-Z)",
    "- `component=\"Z\"`: extract Z component (vertical component)",
    "- `sampling_rate=100`: target sampling rate 100 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set output directory and create PNW processor\n",
    "# auto_download=True: automatically download missing data\n",
    "# use_hf=False: use ModelScope instead of Hugging Face\n",
    "# force_download=True: force re-download to overwrite existing files\n",
    "# component_order=\"ENZ\": original component order in HDF5\n",
    "# component=\"Z\": extract vertical component\n",
    "# sampling_rate=100: target sampling rate in Hz\n",
    "output_dir = Path('datasets/PNW')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "csv_path = output_dir / 'PNW.csv'\n",
    "hdf5_path = output_dir / 'PNW.hdf5'\n",
    "\n",
    "print(f'Creating PNW processor...')\n",
    "processor = PNW(\n",
    "    csv_path=str(csv_path),\n",
    "    hdf5_path=str(hdf5_path),\n",
    "    output_polarity=str(output_dir),\n",
    "    component_order='ENZ',\n",
    "    component='Z',\n",
    "    sampling_rate=100,\n",
    "    auto_download=True,\n",
    "    use_hf=False,\n",
    "    force_download=True\n",
    ")\n",
    "\n",
    "print(f'Starting processing...')\n",
    "processor.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Processed PNW Data",
    "",
    "Read processed HDF5 file, view basic dataset information and polarity distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read processed HDF5 file and inspect dataset information\n",
    "# X: waveform data, Y: polarity labels, p_pick: P-wave arrival points\n",
    "with h5py.File(processor.output_polarity, 'r') as f:\n",
    "    X = f['X'][:]\n",
    "    Y = f['Y'][:]\n",
    "    p_pick = f['p_pick'][:]\n",
    "    \n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"Label shape: {Y.shape}\")\n",
    "print(f\"P-pick shape: {p_pick.shape}\")\n",
    "print(f\"n Polarity distribution:\")\n",
    "unique, counts = np.unique(Y, return_counts=True)\n",
    "label_names = ['positive', 'negative', 'undecidable']\n",
    "for u, c in zip(unique, counts):\n",
    "    print(f\"  {label_names[u] if u < len(label_names) else str(u)}: {c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanced Sampling for PNW Dataset",
    "",
    "PNW dataset is recommended to use **min-based** balanced sampling strategy to ensure equal proportions of positive, negative, and undecidable samples.",
    "",
    "**Min-Based Strategy**:",
    "- Count samples in each polarity class (positive, negative, undecidable)",
    "- Determine the minimum count among all classes",
    "- Sample equally from each class up to the minimum count",
    "- Final distribution: positive = 1/3, negative = 1/3, undecidable = 1/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create balanced dataloader for PNW dataset using min-based strategy\n",
    "from seispolarity.generate import BalancedPolarityGenerator\n",
    "\n",
    "# Reload PNW data with all three labels (positive, negative, undecidable)\n",
    "pnw_datasets_full = WaveformDataset(\n",
    "    path=pnw_datasets,\n",
    "    name=\"PNW_Full\",\n",
    "    preload=True,\n",
    "    allowed_labels=[0, 1, 2],  # Include all three labels\n",
    "    data_key=\"X\",\n",
    "    label_key=\"Y\",\n",
    "    p_pick_position=None,\n",
    "    pick_key=\"p_pick\",\n",
    "    crop_left=200,\n",
    "    crop_right=200\n",
    ")\n",
    "\n",
    "# Create balanced generator using min-based strategy\n",
    "balanced_generator = BalancedPolarityGenerator(\n",
    "    pnw_datasets_full,\n",
    "    strategy=\"min_based\"  # Recommended for PNW dataset\n",
    ")\n",
    "\n",
    "# Get balanced dataloader\n",
    "balanced_loader = balanced_generator.get_dataloader(\n",
    "    batch_size=256,\n",
    "    num_workers=4,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"Original dataset size: {len(pnw_datasets_full)}\")\n",
    "print(f\"Label distribution: {pnw_datasets_full.label_distribution}\")\n",
    "print(f\"Balanced dataset size: {len(balanced_generator)}\")\n",
    "print(f\"Balanced dataloader created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load PNW Data Using WaveformDataset",
    "",
    "Load processed PNW data using WaveformDataset class, can conveniently access individual samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PNW data using WaveformDataset class\n",
    "# preload=True: load all data into memory\n",
    "# allowed_labels=[0,1]: only use positive and negative labels\n",
    "# crop_left=200, crop_right=200: extract 400 samples centered at P-wave arrival\n",
    "from seispolarity.data import WaveformDataset\n",
    "\n",
    "# PNW Datasets\n",
    "pnw_datasets = processor.output_polarity\n",
    "pnw_datasets = WaveformDataset(\n",
    "    path=pnw_datasets,\n",
    "    name=\"PNW\",\n",
    "    preload=True,\n",
    "    allowed_labels=[0,1],\n",
    "    data_key=\"X\",\n",
    "    label_key=\"Y\",\n",
    "    p_pick_position=None,\n",
    "    pick_key=\"p_pick\",  # Use p_pick as P-wave arrival point\n",
    "    crop_left=200,   # 300 - 200 = 100\n",
    "    crop_right=200   # 300 + 200 = 500 (total 400 sampling points)\n",
    ")\n",
    "\n",
    "# View data\n",
    "print(f\"Dataset size: {len(pnw_datasets)}\")\n",
    "print(f\"n Access first sample:\")\n",
    "waveform, metadata = pnw_datasets[0]\n",
    "print(f\"Waveform data shape: {waveform.shape}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seispolarity",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}